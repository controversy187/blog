[{"content":"My Todoist Was a Mess I\u0026rsquo;ve been a loyal Todoist user for years. It\u0026rsquo;s been my trusty sidekick for keeping my work organized. But recently, things got a little out of hand. A small internal restructure at the organization I work for meant my workload grew significantly. More projects, more stakeholders, and a couple more people on my team. And a constant stream of new tasks hitting my inbox. I was struggling to keep my head above water. I was busy, but I wasn\u0026rsquo;t making progress on the things that actually mattered.\nI knew I needed to do something different. One of my teammates had been experimenting with the Google ADK (Agent Development Kit) and it got me thinking: could I build my own AI assistant to help me make sense of the chaos?\nWhy I Chose Google ADK I\u0026rsquo;d seen some cool demos of Google ADK, but I wanted to see if I could use it to solve a real-world problem. My teammate was using it to pull data in from BigQuery and make sense of it. My problem was simple: I needed to figure out what to work on next. I needed a way to cut through the noise and find the high-impact tasks that would actually move the needle.\nBuilding My AI Assistant I\u0026rsquo;m not a professional developer, but I like to tinker. I started by sketching out what I wanted my AI assistant to do:\nTalk to Todoist to get my tasks. Help me figure out which tasks were most important. Give me guidance on what to work on next. With Google ADK, I was able to create a few different \u0026ldquo;agents\u0026rdquo; that worked together:\nA Smart Prioritization Agent that looks at how recent a task is, its impact, and how much effort it will take. A Project Manager Agent that helps me break down big, scary tasks into smaller, more manageable ones. A Coordinator Agent that figures out which agent to send my requests to. I also set up a simple rule: all the details about a task go in the description, and any updates or decisions get logged as comments. This keeps my Todoist nice and tidy.\nHow It Works - A Refinement Session Most of my tasks in Todoist were simply one-liners where I captured a thought of a task, to be done or prioritized later. I didn\u0026rsquo;t want to lose track of them. But they didn\u0026rsquo;t have a lot of context or detail. So the first thing I needed to do was to refine my backlog of tasks. My ADK tool does just that, when I tell it that I want to. It pulls in all my open tasks, reads the descriptions and comments, and asks me questions to fill in any blanks.\nHow It Works - Prioritization Once I had all my tasks refined, I can ask my agents to tell me my top priority tasks for the day, and it will present me with a game plan. These are prioritized based on how recent the most recent action was taken on a task, what the anticipated impact of the task is, and how much effort my next action is.\nFinally, it updates my tasks in Todoist with the new priorities and any notes we discussed.\nThe Results The difference has been night and day. Instead of staring at a giant list of tasks, I get a clear, actionable plan every morning. I know what I need to work on, why it\u0026rsquo;s important, and what the next steps are. I feel like I\u0026rsquo;m back in the driver\u0026rsquo;s seat, making real progress on the things that matter.\nBugs The most common bug that I have is that sometimes the Agent says it will wait for my input, but then it goes ahead and executes whatever changes it wants to. As a safeguard, I don\u0026rsquo;t have an tool set up for completing a Task. I don\u0026rsquo;t want to lose any tasks if I\u0026rsquo;m not paying super close attention to it. Plus, I don\u0026rsquo;t want to give away that task-completing-dopamine-hit to anyone other than me. Gotta feed my addiction ;)\nAlso, one time it created four copies a task. So watch out for that.\nWhat I Learned This was my first time really diving into Google ADK, and it was a lot of fun. I learned a ton about how to design and build AI agents, and I got to play with some cool new technology. But more importantly, I built something that actually makes my life easier.\nIf you\u0026rsquo;re feeling buried in your to-do list, take a look at my project. It\u0026rsquo;s a somple tool, and sometimes the best way to learn something new is to build something that solves your own problems.\n","permalink":"https://brettgfitzgerald.com/posts/how-i-used-google-adk-and-ai-agents-to-take-control-of-my-todoist-backlog/","summary":"How I went from drowning in tasks to finding clarity by building a custom AI assistant with Google\u0026rsquo;s Agent Development Kit.","title":"Taming My Todoist Beast with Google ADK and AI Agents"},{"content":"Delving into Cursor Ok, I\u0026rsquo;m late to the game. I just started using Cursor to write code. To be fair, writing code isn\u0026rsquo;t really part of my day-to-day job as a Product Manager for an advanced data analytics team, but I wanted to scratch that \u0026ldquo;builder\u0026rdquo; itch in me. Also, I wanted better data than what is available through Jira\u0026rsquo;s API. That means I need to write some code, probably in Python since that\u0026rsquo;s my jam. And why not use these AI tools that everyone else is using? But which one(s) should I use?\nCursor vs. Windsurf vs. Gemini Code Assist vs. Others Cursor. Why? No reason. Gotta start somewhere, and that\u0026rsquo;s what the kids are talking about.\nGetting set up Super simple to get Cursor running. Create an account, download the software, and go. Up and running. It looks very familiar (I guess it\u0026rsquo;s a fork of VSCode, which itself resembles Sublime Text, etc.). There\u0026rsquo;s a file browser in the left sidebar, and primary tabbed coding window. In Cursor, though, there\u0026rsquo;s a chatbox on the right that connects to their AI agent. After signup, you\u0026rsquo;re given two weeks of their Pro version for free. I honestly don\u0026rsquo;t know what their free version includes. That was really hard to determine on their website. Full disclosure, I still don\u0026rsquo;t know. Regardless, that\u0026rsquo;s about all you need to get setup.\nFirst steps Not knowing where to start, I typed in the description of the application I wanted to build. I\u0026rsquo;ve worked with LLMs enough to know to ask if it has any questions for me before it starts doing anything. Sure enough, it asked about technologies to use, and some basic structure questions. Once I answered those, it started writing my code for me! It proposed several files and I blindly accepted the proposals. In short order, I had a basic application running!\nIterating The app itself wasn\u0026rsquo;t worth using yet. Several things were non-functional or looked terrible, but I started to correct the issues one at a time. Through this entire process, I didn\u0026rsquo;t write any code. I simply described the change I wanted to make, and Cursor made a suggestion. I accepted it, and tested the results, going back and forth with the agent. I hear a lot about Cursor\u0026rsquo;s superpower: Tab completion. Describe something, hit Tab, and Cursor fills in the rest. I still haven\u0026rsquo;t used that. The Agentic build is doing everything I ask of it.\nLimitations Eventually, my conversation started losing context. A little note at the bottom of the chat window informed me that starting a new chat will yield better results. But would Cursor pick up where it left off? It turned out, no. A new chat was a new chat. It had the context of the codebase, but only the details of the files that I specifically mentioned. This floundering and context-loss made me realize I needed a better way to guide Cursor, which led me to\u0026hellip;\nA Project Plan As a recovering Agilist, I don\u0026rsquo;t like having a plan. I like to just build things. But a plan gives a person a larger context for what their work does, where it leads, and what it fits into. And that\u0026rsquo;s just what a coding agent needs. So I stopped building for a bit, then told Cursor what my project goals are, and asked it to create a markdown file describing the project, building a checklist of incremental steps we would need to accomplish the project. It happily complied! From that point on, as we accomplished tasks, we checked them off, started a new chat, and picked up right where we left off. Tagging the project plan and the relevant files in a new chat very quickly reacclimated Cursor to what we were doing.\nMore recently, as features that I\u0026rsquo;m building into this application are more sizeable, I\u0026rsquo;m creating Feature plans in addition to the Project plan. So I can give Cursor the overall context of the project, then give it the more granular context of the feature we\u0026rsquo;re building. Keeping these agentic chats small seems to keep them more intellegent.\nBug loops I did stumble on some long loops a bug being introduced, then three or four steps of remediation, then it reintroduced the same bug again. As a concise example, I\u0026rsquo;m new to Big Query and was asking for Cursor to store and update some Big Query records.\nMe: Grab the data from the API and update the table in BQ with it. Cursor: Sure, here\u0026rsquo;s the code. Me: I ran it and it\u0026rsquo;s adding every record as a new record. I want to update the existing records, and add any new ones. Think \u0026ldquo;Upsert\u0026rdquo;. Cursor: Got it. Here\u0026rsquo;s the new code that adds new records and updates existing ones. Me: I ran that, and now Big Query is complaining about not updating a streaming buffer. Cursor: That makes sense. The streaming buffer hasn\u0026rsquo;t finished writing to the table from our last operation, so you can\u0026rsquo;t update those records. I\u0026rsquo;ll refactor the code to accommodate this by creating new rows for each record we get back from the API Me: No, that\u0026rsquo;s where we started!\nIn order to break out of some of these loops, I had to do some learning (from a co-worker) and learned about Merging records. I mentioned that to Cursor, and it quickly leveraged that method to accomodate the streaming buffers.\nFinal Thoughts I described this to my wife. I like building things and solving problems. I used to write code for a living, but I have a horrible memory. I knew how I wanted to solve a problem, but I spent so much time looking up coding references, examples, or debugging things that seemed pretty far into the weeds. Solving the problems was fun, but writing the code was more of a tedius hoop I had to jump through. Heaven forbid I had to go back through someone else\u0026rsquo;s code to try and discover what they were attempting to do!\nCursor has reignited my joy in coding. I am focused on building and solving problems, not remembering syntax and keeping a complex process flow in my active memory. I can delegate the detailed parts to an AI agent who is, frankly, better at keeping them straight. I\u0026rsquo;m learning how to interact with the agent in a way that we both meet with success. Small steps, incremental value delivery. Tight feedback loops. It\u0026rsquo;s all that agile stuff. But the fundamental agile stuff, not the meetings, roles, process, and Agile-Industry.\nIt\u0026rsquo;s fun.\nAfter my two week free Pro trial, the Agent chat just threw errors at me. It said I should try again later, but I never got it to work. I did end up paying the $20 / month for the paid pro version so that I could continue building my application. Frankly, I\u0026rsquo;m getting excited again about building more things. Ideas keep coming like they used to. When I was new to programming and I naively felt like I could build anything with a handful of for loops and if statements. The feeling of ability seemed to unlock so many ideas. Now I\u0026rsquo;m feeling that excitement again. Is Cursor (and agentic programming in general) perfect? Nope! But it\u0026rsquo;s really good, and it\u0026rsquo;s going to get better!\n","permalink":"https://brettgfitzgerald.com/posts/delving-into-cursor/","summary":"\u003ch2 id=\"delving-into-cursor\"\u003eDelving into Cursor\u003c/h2\u003e\n\u003cp\u003eOk, I\u0026rsquo;m late to the game. I just started using \u003ca href=\"https://cursor.sh\"\u003eCursor\u003c/a\u003e to write code. To be fair, writing code isn\u0026rsquo;t really part of my day-to-day job as a Product Manager for an advanced data analytics team, but I wanted to scratch that \u0026ldquo;builder\u0026rdquo; itch in me. Also, I wanted better data than what is available through Jira\u0026rsquo;s API. That means I need to write some code, probably in Python since that\u0026rsquo;s my jam. And why not use these AI tools that everyone else is using? But which one(s) should I use?\u003c/p\u003e","title":"Cursor AI: Rediscovering the Joy of Code (A PM's Journey)"},{"content":"My Journey with MCP Servers I recently learned of MCP (Model Control Protocol) servers through a post on Hacker News. The premise seems really neat. MCP is essentially a protocol that allows AI models like Claude to interact with external tools and services through a standardized interface. I can write a very simple server and create \u0026ldquo;tools\u0026rdquo; for the Claude.ai desktop application to connect to and use. The example in the post created some tools that gave Claude access to read and write to the local filesystem (unrestricted, by the way). The original intent was to have Claude write some application. I cloned and ran the sample MCP server from the article to play with it, and was immediately impressed. This unlocks so many opportunities to integrate an LLM with countless services!\nHold on to that thought\u0026hellip;\nMy Second Brain For the past several years, I\u0026rsquo;ve been using Tiago Forte\u0026rsquo;s Build a Second Brain method using Obsidian.md for my second brain. I implemented the PARA Method for organization, and create a Daily Note every day to link my chronological life to my disorganized brain. It\u0026rsquo;s been a good system, even if I don\u0026rsquo;t use it to it\u0026rsquo;s fullest. At the very least, I have all my notes synced with me between my desktop, laptop, and phone, thanks to Syncthing. That being said, Obsidian\u0026rsquo;s search capabilities are relatively lackluster.\nThis is where my MCP server can help.\nGetting things going To get it all setup, I basically cloned the MCP server linked above, and then set it up as they described, creating the server config in the Claude Desktop app. Since I\u0026rsquo;m running Linux, I had to hack around a bit to get the Windows Claude client running, but it works fine. With the MCP server connected, I now showed that I had several tools available to Claude.\nAfter some sample queries, I validated that Claude now had full access to my filesystem!\nPlumbing the depths of my second brain\u0026hellip; Since I write a Daily Note every day, I first asked Claude to summarize my daily notes for the month of March 2025. It came up with accurate and surprisingly detailed insights.\nMarch 2025 Daily Notes Summary Personal Life Family Activities: Started the month at ****** with the ****** and ****** families, though you noted it was chaotic with misaligned schedules Went skiing with ****** at Crystal Mountain on March 10th, where you had a meaningful father-son conversation about life and relationships Your daughter ****** attended Middle School Ministry several times References to your family (******, ******, ******, ******) appear consistently throughout the month Fitness: Maintained consistent workout schedule with 15 recorded workout days Primarily practiced Jiu-Jitsu at ****** (both gi and nogi classes) Also incorporated running into your fitness routine Tracked your weight throughout the month, ranging from 179 lbs to 187 lbs, with an average around 182 lbs Spiritual Practice: Maintained daily quiet time starting mid-month (March 18-31) Studied the Gospel of Matthew, progressing sequentially from Matthew 12:38 through Matthew 14:33 Each quiet time session appears well-documented with dedicated notes Professional Life Regular Meetings: ****** (almost daily) Weekly kickoff meetings (Mondays) One-on-one meetings with various team members including ******, ******, and ****** Key Projects: ****** Rush Orders project with weekly check-ins ****** project with multiple coordination meetings Corporate Injury Analysis work Supply Chain ****** activities and meetings Non******stock ETA modeling work (created ******) Professional Development: Participated in Looker Studio training for data visualization Worked on Google Maps Optimization POC Set up Gemini in VSCode Explored Jira metrics via API People Management: Reached out to ****** about a ****** Provided feedback on ******\u0026#39;s Flow Metrics presentation Worked with various team members including ******, ******, ******, and ****** Your month shows a balanced life with consistent attention to physical fitness, spiritual growth, family time, and professional responsibilities, with a particular focus on data and supply chain projects at work. This was great! For years, my Second Brain has been a storage device. I had the ability to go back and manually retrieve that information, but I had to read the notes into my short-term (actual) brain, and hold it there while I search for other information to connect it to. Obsidian and the Second Brain method make this simpler by encouraging the use of internal links in notes, but now I had another tool for synthesizing meaningful information from all these connections!\nCreating Notes Equipped with a tool for analyzing my second brain, I turned toward project management. I\u0026rsquo;ve had a few ideas for side projects that I wanted to flesh out a bit. I\u0026rsquo;ve worked with LLMs in the past to bounce ideas off and refine some thoughts, but now I could generate documentation around these ideas, store that information, and retrieve it later for ongoing processing and development! I took a conversation about a project I\u0026rsquo;m thinking through, described my desired goal, and then asked Claude to develop a plan for a low-code, low-cost MVP to test market fit. It described the approach, I refined it a bit, and then asked Claude to store the project documentation in my Obsidian Vault. Boom, project plan and action steps created!\nReflection MCP Servers seem extremely powerful. For such a long time, LLMs have seemed contained to limited use cases. Plugins for code editors have allowed functionality in coding and chatbots are common. Further integrations have required the use of APIs and coding to leverage the power of LLMs in other contexts. Now, with MCP Servers, it really feels like we have simple-to-create interfaces that allow LLMs to interact with the rest of the digital world. What will you create?\n","permalink":"https://brettgfitzgerald.com/posts/mcp-server-experiences/","summary":"\u003ch2 id=\"my-journey-with-mcp-servers\"\u003eMy Journey with MCP Servers\u003c/h2\u003e\n\u003cp\u003eI recently learned of MCP (Model Control Protocol) servers through a \u003ca href=\"https://news.ycombinator.com/item?id=43410866\"\u003epost on Hacker News\u003c/a\u003e. The premise seems really neat. MCP is essentially a protocol that allows AI models like Claude to interact with external tools and services through a standardized interface. I can write a very simple server and create \u0026ldquo;tools\u0026rdquo; for the Claude.ai desktop application to connect to and use. The example in the post created some tools that gave Claude access to read and write to the local filesystem (unrestricted, by the way). The original intent was to have Claude write some application. I cloned and ran the \u003ca href=\"https://github.com/ZbigniewTomanek/my-mcp-server\"\u003esample MCP server\u003c/a\u003e from the article to play with it, and was immediately impressed. This unlocks so many opportunities to integrate an LLM with countless services!\u003c/p\u003e","title":"Obsidian, MCP Servers, and Supercharging Your Second Brain with AI"},{"content":"A videography hobbyist In my free time, I like shooting videos of my family\u0026rsquo;s adventures and doing some basic editing. I shoot on my cellphone and a GoPro. For the past several years, I have rendered my final projects in 1080p at 24 frames per second. I liked the ability to shoot in 4k and still \u0026ldquo;zoom in\u0026rdquo; digitally to 1080. That also let me shoot slow motion video at 1080, and match my final render resolution. I recently got a newer GoPro, so now I can shoot 4k at 120 fps, which allows me slow down to 20% speed if I render my final project at 24 fps.\nWith this advent of being able to shoot slow motion in 4k resolution, I decided to start rendering my projects in 4k, by default. I\u0026rsquo;m also experimenting with doing very quick edits, just splicing the day\u0026rsquo;s footage together, applying automatic color balancing per-clip, and then rendering at 60fps. This is more of a \u0026ldquo;home movie\u0026rdquo; of a day or event, rather than a curated, edited highlight video. I do all this in Davinci Resolve. Previously, I would be able to render my 1080 videos at 24fps and be happy with the file size and quality of picture. Now that I am rendering at four times the resolution and two and a half times the framerate, my output filesize has ballooned, and I need to pay better attention to my compression.\nI want to find a good balance between output filesize and quality for my home movies.\nComparison of projects In the past, I would shoot for around 100 megabytes per minute of rendered video. So a 5 minute video, rendered at a resolution of 1080, at 24 frames per second would come in around 500 MB. For videos I really spent time on, I would bump up my quality settings and I\u0026rsquo;d be happy with a 3 gig file for a 5 minute video.\nI recently rendered a video using Davinci Resolve\u0026rsquo;s 4k \u0026ldquo;Master\u0026rdquo; preset. So a resolution of 4k, at 60 frames per second, and a duration of 22 minutes came in at a whopping 75 gigabytes (~3.4 GB / min). I used Resolve\u0026rsquo;s \u0026ldquo;YouTube\u0026rdquo; preset, and that reduced the filesize to 1.8 GB.(~80 MB / min). That is a significant difference!\nFor reference, my input files, shot on the GoPro Hero 13 were shot in 4k, mostly at 120 fps. They totaled 18.2GB, so my rendered file was actually four times larger than my source material!\nThe two questions I have are:\nWhat is the difference in output files between these two? Is there a noticeable difference in visible quality? Differences in objective data I wrote a python script that compares various aspects of the videos. I also ran them through the various presets in Handbrake to see how they compare. The video is 21:49 long. These are the results of that comparison, in order of increasing filesize.\nFilename Bitrate (kbps) Resolution Framerate (FPS) Video Codec Filesize Source Video (Sample).MP4 120000 3840x2160 119.88 hevc 67 MB Resolve - YouTube - h264.mp4 11618 3840x2160 60 h264 1.8 GB Resolve - YouTube - h265.mp4 10566 3840x2160 60 hevc 1.7 GB Resolve - Master - h264 - HandBrake - Fast.mp4 37948 3840x2160 60 hevc 6 GB Resolve - Master - h264 - HandBrake - VeryFast.mp4 41025 3840x2160 60 hevc 6.5 GB Resolve - Master - h264 - HandBrake - HQ.mp4 57001 3840x2160 60 hevc 9 GB Resolve - Master - h264 - HandBrake - Super HQ.mp4 78210 3840x2160 60 hevc 12.5 GB Resolve - Master - h265.mp4 473927 3840x2160 60 h264 75.7 GB Resolve - Master - h264.mp4 474208 3840x2160 60 h264 75.8 GB Obviously, Handbrake is going a good job at compressing the video, and lowering the bitrate, thus reducing filesize. But how do the videos actually look?\nSubjective comparison Here are images captured from each of the above videos.\nDavinci Resolve, YouTube preset, h264 Davinci Resolve, YouTube Preset, h265 Handbrake, Fast Handbrake, Very Fast Handbrake, High Quality Handbrake, Super High Quality Davinci Resolve, Master - h264 Davinci Resolve, Master - h265 In these very specific examples, you can immediately see that the DaVinci Resolve YouTube presets are not good. The h264 version shows artifiacts on the right side of the frame and all detail in the snow on the ground is completely lost. Interestingly, the h265 codec doesn\u0026rsquo;t lose as much detail, and is slightly smaller. In the case were you need a small file, it seems like the h265 does a better job at these lower bitrates.\nWhen we jump up into the Handbrake re-encodes, things get noticeably better. Honestly, from the still frames it\u0026rsquo;s very hard (for me) to tell the difference between these images, all the way through to the masters. Even when I watch the playback of the videos themselves, I\u0026rsquo;m hard pressed to see any difference. It could be that the source clips themselves only have a 120Mbps bitrate, and we\u0026rsquo;re re-encoding at a higher bitrate for the masters (474Mbps).\nConclusions To really judge this fairly, I probably should have rendered everything out from DaVinci Resolve and manually adjusted the bitrate. Based on these tests, though, I\u0026rsquo;m not seeing a noticeable loss in quality between the 474Mbps best quality from Resolve and a re-encoded to 78Mbps in Handbrake. For the time being, I\u0026rsquo;m planning to render out from Resolve and limiting my bitrate to 80Mbps. That\u0026rsquo;s only 590 MB or so per minute of video, which isn\u0026rsquo;t bad for what I\u0026rsquo;m doing with them.\n","permalink":"https://brettgfitzgerald.com/posts/video-compression-analysis/","summary":"\u003ch2 id=\"a-videography-hobbyist\"\u003eA videography hobbyist\u003c/h2\u003e\n\u003cp\u003eIn my free time, I like shooting videos of my family\u0026rsquo;s adventures and doing some basic editing. I shoot on my cellphone and a GoPro. For the past several years, I have rendered my final projects in 1080p at 24 frames per second. I liked the ability to shoot in 4k and still \u0026ldquo;zoom in\u0026rdquo; digitally to 1080. That also let me shoot slow motion video at 1080, and match my final render resolution. I recently got a newer GoPro, so now I can shoot 4k at 120 fps, which allows me slow down to 20% speed if I render my final project at 24 fps.\u003c/p\u003e","title":"Video Compression Analysis"},{"content":"Building a large language model from scratch I\u0026rsquo;m a machine learning / A.I. hobbyist. The technologies fascinate me, and I can\u0026rsquo;t seem to learn enough about them. Sebastian Raschka\u0026rsquo;s book, Build a Large Language Model (From Scratch) caught my eye. I don\u0026rsquo;t recall how I stumbled on it, but I found it when it was still in early access from Manning Publications. I purchased it, and started working through it as the final chapters were being written and released. I just completed the book and all the included work and loved every minute of it.\nMy approach A while ago, I read some advice about learning programming from digital books and tutorials. The advice was to never copy and paste code from samples but to hand-type all the code. I took that approach with this book. I typed every single line of code (except for a couple of blocks which were highly repetitive and long). You can see all my work here: https://github.com/controversy187/build-a-large-language-model\nI did my best to work in section chunks. I didn\u0026rsquo;t want to start a section unless I had the time dedicated to completing it. Some sections are pretty short, others are fairly involved and time-consuming.\nI built this in Jupyter Notebooks on my laptop, which is pretty underpowered for this type of work. The premise of the book was that you can build an LLM on consumer hardware, and it can perform decently well. As I\u0026rsquo;m writing this, I\u0026rsquo;m currently fine-tuning my model locally. My model is about 50 steps into a 230-step tuning, and I just crossed the 20-minute execution time mark. The earlier code samples ran quicker, but the last few sections used larger models, which slowed things down considerably.\nI didn\u0026rsquo;t do most of the supplemental exercises. I tend to have an \u0026ldquo;I want to do ALL THE THINGS!\u0026rdquo; personality. The drawback is that if I take the time to do all the things, I eventually get long-term distracted and never actually finish what I started. So I sort of rushed through this book. I even took several weeks off around Christmas and New Year\u0026rsquo;s. But I got back into it and powered through the last few chapters.\nSo, more or less, I read through the chapters and wrote all the mandatory coding assignments.\nLearnings What can I tell you about large language models? A lot more than I could before I started this book, but certainly not all the things the author attempted to teach me. I\u0026rsquo;ll summarize my understanding, but I could be wrong about some of these things, and I most certainly forgot or misunderstood others.\nTokenization \u0026amp; Vocabulary A large language model starts its life by building a vocabulary of text. A massive amount of text is distilled down into a list of unique words. Each word is then translated into an integer because computers like numbers more than they like words. This process is referred to as \u0026ldquo;tokenization\u0026rdquo;, where the word is replaced with a numerical token. So now we have a list of unique tokens, which is the vocabulary of the large language model.\n# Build a more advanced tokenizer text = \u0026#34;Hello, world. Is this-- a test?\u0026#34; result = re.split(r\u0026#39;([,.:;?_!\u0026#34;()\\\u0026#39;]|--|\\s)\u0026#39;, text) result = [item.strip() for item in result if item.strip()] print(result) # Outputs \u0026#34;[\u0026#39;Hello\u0026#39;, \u0026#39;,\u0026#39;, \u0026#39;world\u0026#39;, \u0026#39;.\u0026#39;, \u0026#39;Is\u0026#39;, \u0026#39;this\u0026#39;, \u0026#39;--\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;test\u0026#39;, \u0026#39;?\u0026#39;]\u0026#34; all_words = sorted(set(result)) vocab_size = len(all_words) print(vocab_size) # Outputs 10 # Display the first 51 tokens in our vocabulary. vocab = {token:integer for integer,token in enumerate(all_words)} for i, item in enumerate(vocab.items()): print(item) # Outputs: (\u0026#39;,\u0026#39;, 0) (\u0026#39;--\u0026#39;, 1) (\u0026#39;.\u0026#39;, 2) (\u0026#39;?\u0026#39;, 3) (\u0026#39;Hello\u0026#39;, 4) (\u0026#39;Is\u0026#39;, 5) (\u0026#39;a\u0026#39;, 6) (\u0026#39;test\u0026#39;, 7) (\u0026#39;this\u0026#39;, 8) (\u0026#39;world\u0026#39;, 9) # In this example, the id 9 represents the word \u0026#34;world\u0026#34;. 5 represents \u0026#34;Is\u0026#34;. etc. This is where my understanding gets fuzzy. We didn\u0026rsquo;t get very far before that happened, \u0026rsquo;eh? Now, we take that massive amount of text we were using earlier to create the vocabulary (or a subset, or totally different text), and we tokenize the entire text. We do this by using the vocabulary we built previously and substituting the words in the training text for their equivalent token value. This is now our training text.\nModel Training \u0026amp; Relationships With that complete, we can \u0026ldquo;train\u0026rdquo; the model. This process involves taking each token in the vocabulary and building a relationship to each other token in the vocabulary, based on those tokens\u0026rsquo; relative positions to each other in the training text. So if the word \u0026ldquo;cat\u0026rdquo; is followed by the word \u0026ldquo;jump\u0026rdquo;, the model records that relationship. But it also records the relationship of the word \u0026ldquo;cat\u0026rdquo; to other words in the text. So \u0026ldquo;jump\u0026rdquo; follows \u0026ldquo;cat\u0026rdquo;, but maybe it does so more frequently when they are close to the word \u0026ldquo;mouse\u0026rdquo;. And maybe less frequently when they are close to the word \u0026ldquo;nap\u0026rdquo;. Recording ALL these relationships would require a massive dataset, so the relationships are mathematically reduced and approximated. There are definitely more technical terms to use, and the book went into them. I definitely forget them, though.\nText Generation Process Now, if you provide a starter text to the model, it will try to complete the text for you. Continuing our example, if I gave the model the text \u0026ldquo;My cat saw a mouse and it\u0026rdquo;, based on the word cat being close to the word mouse, it might predict the word \u0026ldquo;jumped\u0026rdquo; to come next. So it appends the word \u0026ldquo;jumped\u0026rdquo; to the text I submitted, and then it takes that whole new sentence and feeds it back into itself. So now the input text is \u0026ldquo;My cat saw a mouse and it jumped\u0026rdquo;. The next output word could be \u0026ldquo;on\u0026rdquo;, so it appends that word and feeds this concatenated output back into its input.\nEvery time it does a loop like this, it tokenizes the entire input (or up to a limit, known as a context limit or context window) and then calculates the most likely next token, then converts it all back to text for us to read. See update\nModel Weights \u0026amp; Distribution Saving all those relationships between the tokens are known as the \u0026ldquo;weights\u0026rdquo; of the model. See update Those can be distributed, so if you train a model on a given training text, you can give that to your friends and they can use those model weights to predict text similar to that training text.\nFine Tuning Fine-tuning is the process of training a model for specific\u0026hellip; things. My mind is getting fuzzier here, so I\u0026rsquo;m not going to go into this deeper. Suffice it to say, that you start with a base language model and continue to train it using specific input and output pairs. In the book, we built a spam classifier that determined if a given message was spam or not, as well as a model that will follow instructions. That\u0026rsquo;s actually the one that\u0026rsquo;s being trained right now as I write this post, so I\u0026rsquo;m not sure how it will turn out. Based on the fact that it\u0026rsquo;s published in a book, I think it will come out just fine.\nSo while I\u0026rsquo;m not completely done with the book, I\u0026rsquo;m very nearly there. I did learn a lot of great concepts, although obviously some of them weren\u0026rsquo;t retained. It would probably behoove me to go back through the book again and quickly breeze through it, in order to refresh my memory and cement my learnings.\nMeta learnings Other than the technical aspects of Large Language Models, what else did I learn through this experience?\nThrough my experiment with typing all the code samples by hand, I can say that my time would have been better spent with a different approach. If I do this again, I\u0026rsquo;ll probably not type all the code snippets, but rather \u0026ldquo;type\u0026rdquo; them in my mind, and really understand what each line does. The times I learned the most were actually when I made a typo and had to go back through my code to debug it. That forced me to understand what was happening so I could figure out what went wrong.\nI learn better with paper, rather than a digital book. I don\u0026rsquo;t know why. I had both available to me, and I read the first couple of chapters in the paper book. That information stuck better. Maybe because it was earlier in the book and simpler to understand, or maybe the format played into it. But I enjoyed it better, regardless.\nI didn\u0026rsquo;t have to \u0026ldquo;figure out\u0026rdquo; anything, and I think that hampered my learning. There are supplemental exercises in the book, where the author gives you a problem and you have to figure out how to solve it. The answers are given in his GitHub repository. That would have slowed me down a lot, but I\u0026rsquo;m very confident that I would have learned the material better.\nWhat\u0026rsquo;s next? I\u0026rsquo;m torn right now. I want to understand this material better, but I wonder if getting into lower-level, specific material might help me understand AI and machine learning better. What will likely happen is that I\u0026rsquo;ll copy and paste this content into Claude.ai and suggest a path forward for me.\nUpdate: 2025-02-17 Sebastian Raschka sent me a kind message in response to this post and clarified some of my thinking. To quote him:\n\u0026ldquo;Every time it does a loop like this, it tokenizes the entire input (or up to a limit, known as a context limit or context window)\u0026rdquo;. You do this initially when you parse the input text. But then you technically don\u0026rsquo;t need to re-tokenize anything. You can leave the generated output in the tokenized form when creating the next token. What I mean is if the text is\n\u0026ldquo;My cat saw a mouse\u0026rdquo;\nThe tokens might be \u0026ldquo;123 1 5 6 99\u0026rdquo; (numbers are arbitrary examples). Then the LLM generates the token 801 for \u0026ldquo;jump\u0026rdquo;. Then you simply use \u0026ldquo;123 1 5 6 99 801\u0026rdquo; as the input for the next word.\nWhen you show the output to the user, then you convert back into text.\n\u0026ldquo;Saving all those relationships between the tokens are known as the “weights” of the model.\u0026rdquo; I would say that relationships between tokens are the attention scores. The model weights are more like values that are involved in computing things like the attention scores (and other things).\nNow that you finished the book, in case you are bored, I do also have some more materials as bonus material in the GitHub repository.\nI\u0026rsquo;d say the GPT-\u0026gt;Llama conversion (https://github.com/rasbt/LLMs-from-scratch/tree/main/ch05/07_gpt_to_llama) and the DPO preference tuning (https://github.com/rasbt/LLMs-from-scratch/blob/main/ch07/04_preference-tuning-with-dpo/dpo-from-scratch.ipynb) are maybe the most interesting ones.\nI also just uploaded some PyTorch tips for increasing the training speed of the model: https://github.com/rasbt/LLMs-from-scratch/tree/main/ch05/10_llm-training-speed\nThese materials are less polished than the book itself, but maybe you\u0026rsquo;ll still find them useful!\n","permalink":"https://brettgfitzgerald.com/posts/build-a-large-language-model/","summary":"\u003ch2 id=\"building-a-large-language-model-from-scratch\"\u003eBuilding a large language model from scratch\u003c/h2\u003e\n\u003cp\u003eI\u0026rsquo;m a machine learning / A.I. hobbyist. The technologies fascinate me, and I can\u0026rsquo;t seem to learn enough about them. Sebastian Raschka\u0026rsquo;s book, Build a Large Language Model (From Scratch) caught my eye. I don\u0026rsquo;t recall how I stumbled on it, but I found it when it was still in early access from Manning Publications. I purchased it, and started working through it as the final chapters were being written and released. I just completed the book and all the included work and loved every minute of it.\u003c/p\u003e","title":"Build a Large Language Model From Scratch"},{"content":"I\u0026rsquo;m a technologist who\u0026rsquo;s followed my curiosity through various roles in software development, agile leadership, and now data analytics. This blog documents my ongoing journey of learning and exploration in technology.\nProfessional Background I got my start in computers by hacking around on a Commodore 64. I distinctly remember loading an ASCII bowling game, and finding out that I could see the source code before running the program. Not knowing what source code was at the time, I simply saw the word \u0026ldquo;BOWLING\u0026rdquo;, as it appeared on the title screen. Being in elementary school at the time, I changed it to \u0026ldquo;POOPING\u0026rdquo;, ran the program, saw my changes, and my life was set on a very specific course.\nFrom these humble beginnings, I went on to study computer networking through college. Upon graduating, I immediately began a career in web development, because CISCO certifications are hard. Early career HTML, CSS, JS, Classic ASP and PHP got me started in the world of software development. As technologies evolved, I barely did, continuing my skillset and going moderately deep in the PHP and WordPress world. I dabbled in AWS architecture in the early AWS days, and eventually found more joy at the intersection of people and technology than I did staying heads down at the keyboard.\nThose interests led me into the world of Agile, and I became a Scrum Master. I loved working with a small focused team, and we did a lot of things that weren\u0026rsquo;t really Scrum, but worked well for us. I ended up drinking the Scaled Agile Framework Cool-Aid, and even did a little SAFe consulting. This led me to Portfolio Manager role.\nTrying to scale Agile was a frustrating experience. I wasn\u0026rsquo;t close to the work, and I didn\u0026rsquo;t feel like I was providing value. In my free time, I was learning about machine learning, artificial intelligence, blockchain technologies, and other technological interests. My passions didn\u0026rsquo;t lie with the Scaled Agile Framework.\nDisillusioned with SAFe, I found an opportunity to be a product manager for a data analytics team. I took a risk and pursued it, and the manager took a risk on me and hired me. That\u0026rsquo;s where our story begins, and the impetus for this website. I\u0026rsquo;m learning a lot, and I want to document what I\u0026rsquo;m learning.\nPersonal Background I spend the bulk of my days in front of a computer. When I\u0026rsquo;m not here, I like to be outside. I enjoy skiing, ultimate frisbee, Brazilian Jiu Jitsu, kiteboarding, hiking, traveling, and pretty much anything active. I like to do these things with family as much as possible, and I also enjoy amateur videography. That allows me to capture memories in a compelling way that I can enjoy with my wife and kids, and extended family.\n","permalink":"https://brettgfitzgerald.com/about/","summary":"About Brett Fitzgerald","title":"About Me"},{"content":"Why? Does the internet need another blog? Definitively, no. Do I have original insights that you will benefit from reading? Most likely not. So what\u0026rsquo;s the point of this blog?\nI recently changed jobs, and I\u0026rsquo;m learning a lot. I retain information better when I describe it to someone. I also have a fear that if I constantly regurgitate my ongoing education to my close family, they will eventually want to murder me. That\u0026rsquo;s where this blog comes in. I\u0026rsquo;m going to teach you what I\u0026rsquo;m learning, so I can learn it better.\nInevitably, I\u0026rsquo;ll forget about this blog. Posts will become less frequent, and then stop completely. At some point, I\u0026rsquo;ll just stop writing here completely. After a while, I\u0026rsquo;ll find a new use for my domain name, and this will cease to exist, except in the ever growing dataset of archive.org. So, let\u0026rsquo;s get on with it!\n","permalink":"https://brettgfitzgerald.com/posts/new-blog/","summary":"\u003ch2 id=\"why\"\u003eWhy?\u003c/h2\u003e\n\u003cp\u003eDoes the internet need another blog? Definitively, no. Do I have original insights that you will benefit from reading? Most likely not. So what\u0026rsquo;s the point of this blog?\u003c/p\u003e\n\u003cp\u003eI recently changed jobs, and I\u0026rsquo;m learning a lot. I retain information better when I describe it to someone. I also have a fear that if I constantly regurgitate my ongoing education to my close family, they will eventually want to murder me. That\u0026rsquo;s where this blog comes in. I\u0026rsquo;m going to teach you what I\u0026rsquo;m learning, so I can learn it better.\u003c/p\u003e","title":"New Blog"}]