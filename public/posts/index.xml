<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Brett Fitzgerald</title><link>https://brettgfitzgerald.com/</link><description>Recent content on Brett Fitzgerald</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://brettgfitzgerald.com/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>Taming My Todoist Beast with Google ADK and AI Agents</title><link>https://brettgfitzgerald.com/posts/how-i-used-google-adk-and-ai-agents-to-take-control-of-my-todoist-backlog/</link><pubDate>Wed, 02 Jul 2025 00:00:00 +0000</pubDate><guid>https://brettgfitzgerald.com/posts/how-i-used-google-adk-and-ai-agents-to-take-control-of-my-todoist-backlog/</guid><description>&lt;h2 id="my-todoist-was-a-mess">My Todoist Was a Mess&lt;/h2>
&lt;p>I&amp;rsquo;ve been a loyal Todoist user for years. It&amp;rsquo;s been my trusty sidekick for keeping my work organized. But recently, things got a little out of hand. A small internal restructure at the organization I work for meant my workload grew significantly. More projects, more stakeholders, and a couple more people on my team. And a constant stream of new tasks hitting my inbox. I was struggling to keep my head above water. I was busy, but I wasn&amp;rsquo;t making progress on the things that actually mattered.&lt;/p>
&lt;p>I knew I needed to do something different. One of my teammates had been experimenting with the &lt;a href="https://github.com/google/adk">Google ADK (Agent Development Kit)&lt;/a> and it got me thinking: could I build my own AI assistant to help me make sense of the chaos?&lt;/p>
&lt;h2 id="why-i-chose-google-adk">Why I Chose Google ADK&lt;/h2>
&lt;p>I&amp;rsquo;d seen some cool demos of Google ADK, but I wanted to see if I could use it to solve a real-world problem. My teammate was using it to pull data in from BigQuery and make sense of it. My problem was simple: I needed to figure out what to work on next. I needed a way to cut through the noise and find the high-impact tasks that would actually move the needle.&lt;/p>
&lt;h2 id="building-my-ai-assistant">Building My AI Assistant&lt;/h2>
&lt;p>I&amp;rsquo;m not a professional developer, but I like to tinker. I started by sketching out what I wanted my AI assistant to do:&lt;/p>
&lt;ul>
&lt;li>Talk to Todoist to get my tasks.&lt;/li>
&lt;li>Help me figure out which tasks were most important.&lt;/li>
&lt;li>Give me guidance on what to work on next.&lt;/li>
&lt;/ul>
&lt;p>With Google ADK, I was able to create a few different &amp;ldquo;agents&amp;rdquo; that worked together:&lt;/p>
&lt;ul>
&lt;li>A &lt;strong>Smart Prioritization Agent&lt;/strong> that looks at how recent a task is, its impact, and how much effort it will take.&lt;/li>
&lt;li>A &lt;strong>Project Manager Agent&lt;/strong> that helps me break down big, scary tasks into smaller, more manageable ones.&lt;/li>
&lt;li>A &lt;strong>Coordinator Agent&lt;/strong> that figures out which agent to send my requests to.&lt;/li>
&lt;/ul>
&lt;p>I also set up a simple rule: all the details about a task go in the description, and any updates or decisions get logged as comments. This keeps my Todoist nice and tidy.&lt;/p>
&lt;h2 id="how-it-works---a-refinement-session">How It Works - A Refinement Session&lt;/h2>
&lt;blockquote>
&lt;p>&lt;img alt="The agent analyzing a task, asking clarifying questions, and proposing a new description and comment" loading="lazy" src="https://brettgfitzgerald.com/posts/how-i-used-google-adk-and-ai-agents-to-take-control-of-my-todoist-backlog/images/TaskAgents1.jpg">&lt;/p>&lt;/blockquote>
&lt;p>Most of my tasks in Todoist were simply one-liners where I captured a thought of a task, to be done or prioritized later. I didn&amp;rsquo;t want to lose track of them. But they didn&amp;rsquo;t have a lot of context or detail. So the first thing I needed to do was to refine my backlog of tasks. My ADK tool does just that, when I tell it that I want to. It pulls in all my open tasks, reads the descriptions and comments, and asks me questions to fill in any blanks.&lt;/p>
&lt;h2 id="how-it-works---prioritization">How It Works - Prioritization&lt;/h2>
&lt;blockquote>
&lt;p>&lt;img alt="The agent presenting a prioritized daily plan, grouping tasks by impact and effort" loading="lazy" src="https://brettgfitzgerald.com/posts/how-i-used-google-adk-and-ai-agents-to-take-control-of-my-todoist-backlog/images/TaskAgents2.jpg">&lt;/p>&lt;/blockquote>
&lt;p>Once I had all my tasks refined, I can ask my agents to tell me my top priority tasks for the day, and it will present me with a game plan. These are prioritized based on how recent the most recent action was taken on a task, what the anticipated impact of the task is, and how much effort my next action is.&lt;/p>
&lt;p>Finally, it updates my tasks in Todoist with the new priorities and any notes we discussed.&lt;/p>
&lt;h2 id="the-results">The Results&lt;/h2>
&lt;p>The difference has been night and day. Instead of staring at a giant list of tasks, I get a clear, actionable plan every morning. I know what I need to work on, why it&amp;rsquo;s important, and what the next steps are. I feel like I&amp;rsquo;m back in the driver&amp;rsquo;s seat, making real progress on the things that matter.&lt;/p>
&lt;h2 id="bugs">Bugs&lt;/h2>
&lt;blockquote>
&lt;p>&lt;img alt="The agent updating Todoist tasks and confirming the new priorities" loading="lazy" src="https://brettgfitzgerald.com/posts/how-i-used-google-adk-and-ai-agents-to-take-control-of-my-todoist-backlog/images/TaskAgents3.jpg">&lt;/p>&lt;/blockquote>
&lt;p>The most common bug that I have is that sometimes the Agent says it will wait for my input, but then it goes ahead and executes whatever changes it wants to. As a safeguard, I don&amp;rsquo;t have an tool set up for completing a Task. I don&amp;rsquo;t want to lose any tasks if I&amp;rsquo;m not paying super close attention to it. Plus, I don&amp;rsquo;t want to give away that task-completing-dopamine-hit to anyone other than me. Gotta feed my addiction ;)&lt;/p>
&lt;p>Also, one time it created four copies a task. So watch out for that.&lt;/p>
&lt;h2 id="what-i-learned">What I Learned&lt;/h2>
&lt;p>This was my first time really diving into Google ADK, and it was a lot of fun. I learned a ton about how to design and build AI agents, and I got to play with some cool new technology. But more importantly, I built something that actually makes my life easier.&lt;/p>
&lt;p>If you&amp;rsquo;re feeling buried in your to-do list, take a look at &lt;a href="https://github.com/controversy187/todoist-adk">my project&lt;/a>. It&amp;rsquo;s a somple tool, and sometimes the best way to learn something new is to build something that solves your own problems.&lt;/p></description></item><item><title>Cursor AI: Rediscovering the Joy of Code (A PM's Journey)</title><link>https://brettgfitzgerald.com/posts/delving-into-cursor/</link><pubDate>Tue, 13 May 2025 00:00:00 -0500</pubDate><guid>https://brettgfitzgerald.com/posts/delving-into-cursor/</guid><description>&lt;h2 id="delving-into-cursor">Delving into Cursor&lt;/h2>
&lt;p>Ok, I&amp;rsquo;m late to the game. I just started using &lt;a href="https://cursor.sh">Cursor&lt;/a> to write code. To be fair, writing code isn&amp;rsquo;t really part of my day-to-day job as a Product Manager for an advanced data analytics team, but I wanted to scratch that &amp;ldquo;builder&amp;rdquo; itch in me. Also, I wanted better data than what is available through Jira&amp;rsquo;s API. That means I need to write some code, probably in Python since that&amp;rsquo;s my jam. And why not use these AI tools that everyone else is using? But which one(s) should I use?&lt;/p>
&lt;h2 id="cursor-vs-windsurf-vs-gemini-code-assist-vs-others">Cursor vs. Windsurf vs. Gemini Code Assist vs. Others&lt;/h2>
&lt;p>Cursor. Why? No reason. Gotta start somewhere, and that&amp;rsquo;s what the kids are talking about.&lt;/p>
&lt;h2 id="getting-set-up">Getting set up&lt;/h2>
&lt;p>Super simple to get Cursor running. Create an account, download the software, and go. Up and running. It looks very familiar (I guess it&amp;rsquo;s a fork of VSCode, which itself resembles Sublime Text, etc.). There&amp;rsquo;s a file browser in the left sidebar, and primary tabbed coding window. In Cursor, though, there&amp;rsquo;s a chatbox on the right that connects to their AI agent. After signup, you&amp;rsquo;re given two weeks of their Pro version for free. I honestly don&amp;rsquo;t know what their free version includes. That was really hard to determine on their website. Full disclosure, I still don&amp;rsquo;t know. Regardless, that&amp;rsquo;s about all you need to get setup.&lt;/p>
&lt;h2 id="first-steps">First steps&lt;/h2>
&lt;p>Not knowing where to start, I typed in the description of the application I wanted to build. I&amp;rsquo;ve worked with LLMs enough to know to ask if it has any questions for me before it starts doing anything. Sure enough, it asked about technologies to use, and some basic structure questions. Once I answered those, it started writing my code for me! It proposed several files and I blindly accepted the proposals. In short order, I had a basic application running!&lt;/p>
&lt;h2 id="iterating">Iterating&lt;/h2>
&lt;p>The app itself wasn&amp;rsquo;t worth using yet. Several things were non-functional or looked terrible, but I started to correct the issues one at a time. Through this entire process, I didn&amp;rsquo;t write any code. I simply described the change I wanted to make, and Cursor made a suggestion. I accepted it, and tested the results, going back and forth with the agent. I hear a lot about Cursor&amp;rsquo;s superpower: Tab completion. Describe something, hit Tab, and Cursor fills in the rest. I still haven&amp;rsquo;t used that. The Agentic build is doing everything I ask of it.&lt;/p>
&lt;h2 id="limitations">Limitations&lt;/h2>
&lt;p>Eventually, my conversation started losing context. A little note at the bottom of the chat window informed me that starting a new chat will yield better results. But would Cursor pick up where it left off? It turned out, no. A new chat was a new chat. It had the context of the codebase, but only the details of the files that I specifically mentioned. This floundering and context-loss made me realize I needed a better way to guide Cursor, which led me to&amp;hellip;&lt;/p>
&lt;h2 id="a-project-plan">A Project Plan&lt;/h2>
&lt;p>As a recovering Agilist, I don&amp;rsquo;t like having a plan. I like to just build things. But a plan gives a person a larger context for what their work does, where it leads, and what it fits into. And that&amp;rsquo;s just what a coding agent needs. So I stopped building for a bit, then told Cursor what my project goals are, and asked it to create a markdown file describing the project, building a checklist of incremental steps we would need to accomplish the project. It happily complied! From that point on, as we accomplished tasks, we checked them off, started a new chat, and picked up right where we left off. Tagging the project plan and the relevant files in a new chat very quickly reacclimated Cursor to what we were doing.&lt;/p>
&lt;p>More recently, as features that I&amp;rsquo;m building into this application are more sizeable, I&amp;rsquo;m creating Feature plans in addition to the Project plan. So I can give Cursor the overall context of the project, then give it the more granular context of the feature we&amp;rsquo;re building. Keeping these agentic chats small seems to keep them more intellegent.&lt;/p>
&lt;h2 id="bug-loops">Bug loops&lt;/h2>
&lt;p>I did stumble on some long loops a bug being introduced, then three or four steps of remediation, then it reintroduced the same bug again. As a concise example, I&amp;rsquo;m new to Big Query and was asking for Cursor to store and update some Big Query records.&lt;/p>
&lt;p>Me: Grab the data from the API and update the table in BQ with it.
Cursor: Sure, here&amp;rsquo;s the code.
Me: I ran it and it&amp;rsquo;s adding every record as a new record. I want to update the existing records, and add any new ones. Think &amp;ldquo;Upsert&amp;rdquo;.
Cursor: Got it. Here&amp;rsquo;s the new code that adds new records and updates existing ones.
Me: I ran that, and now Big Query is complaining about not updating a streaming buffer.
Cursor: That makes sense. The streaming buffer hasn&amp;rsquo;t finished writing to the table from our last operation, so you can&amp;rsquo;t update those records. I&amp;rsquo;ll refactor the code to accommodate this by creating new rows for each record we get back from the API
Me: No, that&amp;rsquo;s where we started!&lt;/p>
&lt;p>In order to break out of some of these loops, I had to do some learning (from a co-worker) and learned about Merging records. I mentioned that to Cursor, and it quickly leveraged that method to accomodate the streaming buffers.&lt;/p>
&lt;h2 id="final-thoughts">Final Thoughts&lt;/h2>
&lt;p>I described this to my wife. I like building things and solving problems. I used to write code for a living, but I have a horrible memory. I knew &lt;em>how&lt;/em> I wanted to solve a problem, but I spent so much time looking up coding references, examples, or debugging things that seemed pretty far into the weeds. Solving the problems was fun, but writing the code was more of a tedius hoop I had to jump through. Heaven forbid I had to go back through someone else&amp;rsquo;s code to try and discover what they were attempting to do!&lt;/p>
&lt;p>Cursor has reignited my joy in coding. I am focused on building and solving problems, not remembering syntax and keeping a complex process flow in my active memory. I can delegate the detailed parts to an AI agent who is, frankly, better at keeping them straight. I&amp;rsquo;m learning how to interact with the agent in a way that we both meet with success. Small steps, incremental value delivery. Tight feedback loops. It&amp;rsquo;s all that agile stuff. But the fundamental agile stuff, not the meetings, roles, process, and Agile-Industry.&lt;/p>
&lt;p>It&amp;rsquo;s fun.&lt;/p>
&lt;p>After my two week free Pro trial, the Agent chat just threw errors at me. It said I should try again later, but I never got it to work. I did end up paying the $20 / month for the paid pro version so that I could continue building my application. Frankly, I&amp;rsquo;m getting excited again about building more things. Ideas keep coming like they used to. When I was new to programming and I naively felt like I could build anything with a handful of for loops and if statements. The feeling of ability seemed to unlock so many ideas. Now I&amp;rsquo;m feeling that excitement again. Is Cursor (and agentic programming in general) perfect? Nope! But it&amp;rsquo;s really good, and it&amp;rsquo;s going to get better!&lt;/p></description></item><item><title>Obsidian, MCP Servers, and Supercharging Your Second Brain with AI</title><link>https://brettgfitzgerald.com/posts/mcp-server-experiences/</link><pubDate>Wed, 02 Apr 2025 00:00:00 -0500</pubDate><guid>https://brettgfitzgerald.com/posts/mcp-server-experiences/</guid><description>&lt;h2 id="my-journey-with-mcp-servers">My Journey with MCP Servers&lt;/h2>
&lt;p>I recently learned of MCP (Model Control Protocol) servers through a &lt;a href="https://news.ycombinator.com/item?id=43410866">post on Hacker News&lt;/a>. The premise seems really neat. MCP is essentially a protocol that allows AI models like Claude to interact with external tools and services through a standardized interface. I can write a very simple server and create &amp;ldquo;tools&amp;rdquo; for the Claude.ai desktop application to connect to and use. The example in the post created some tools that gave Claude access to read and write to the local filesystem (unrestricted, by the way). The original intent was to have Claude write some application. I cloned and ran the &lt;a href="https://github.com/ZbigniewTomanek/my-mcp-server">sample MCP server&lt;/a> from the article to play with it, and was immediately impressed. This unlocks so many opportunities to integrate an LLM with countless services!&lt;/p>
&lt;p>Hold on to that thought&amp;hellip;&lt;/p>
&lt;h2 id="my-second-brain">My Second Brain&lt;/h2>
&lt;p>For the past several years, I&amp;rsquo;ve been using Tiago Forte&amp;rsquo;s &lt;a href="https://www.buildingasecondbrain.com/">Build a Second Brain&lt;/a> method using Obsidian.md for my second brain. I implemented the &lt;a href="https://fortelabs.com/blog/para/">PARA Method&lt;/a> for organization, and create a Daily Note every day to link my chronological life to my disorganized brain. It&amp;rsquo;s been a good system, even if I don&amp;rsquo;t use it to it&amp;rsquo;s fullest. At the very least, I have all my notes synced with me between my desktop, laptop, and phone, thanks to Syncthing. That being said, Obsidian&amp;rsquo;s search capabilities are relatively lackluster.&lt;/p>
&lt;p>This is where my MCP server can help.&lt;/p>
&lt;h2 id="getting-things-going">Getting things going&lt;/h2>
&lt;p>To get it all setup, I basically cloned the MCP server linked above, and then set it up as they described, creating the server config in the Claude Desktop app. Since I&amp;rsquo;m running Linux, I had to &lt;a href="https://github.com/aaddrick/claude-desktop-debian">hack around a bit&lt;/a> to get the Windows Claude client running, but it works fine. With the MCP server connected, I now showed that I had several tools available to Claude.&lt;/p>
&lt;p>&lt;img alt="Available Tools" loading="lazy" src="https://brettgfitzgerald.com/posts/mcp-server-experiences/available-tools.png">&lt;/p>
&lt;p>After some sample queries, I validated that Claude now had full access to my filesystem!&lt;/p>
&lt;h2 id="plumbing-the-depths-of-my-second-brain">Plumbing the depths of my second brain&amp;hellip;&lt;/h2>
&lt;p>Since I write a Daily Note every day, I first asked Claude to summarize my daily notes for the month of March 2025. It came up with accurate and surprisingly detailed insights.&lt;/p>
&lt;pre tabindex="0">&lt;code>March 2025 Daily Notes Summary
Personal Life
Family Activities:
Started the month at ****** with the ****** and ****** families, though you noted it was chaotic with misaligned schedules
Went skiing with ****** at Crystal Mountain on March 10th, where you had a meaningful father-son conversation about life and relationships
Your daughter ****** attended Middle School Ministry several times
References to your family (******, ******, ******, ******) appear consistently throughout the month
Fitness:
Maintained consistent workout schedule with 15 recorded workout days
Primarily practiced Jiu-Jitsu at ****** (both gi and nogi classes)
Also incorporated running into your fitness routine
Tracked your weight throughout the month, ranging from 179 lbs to 187 lbs, with an average around 182 lbs
Spiritual Practice:
Maintained daily quiet time starting mid-month (March 18-31)
Studied the Gospel of Matthew, progressing sequentially from Matthew 12:38 through Matthew 14:33
Each quiet time session appears well-documented with dedicated notes
Professional Life
Regular Meetings:
****** (almost daily)
Weekly kickoff meetings (Mondays)
One-on-one meetings with various team members including ******, ******, and ******
Key Projects:
****** Rush Orders project with weekly check-ins
****** project with multiple coordination meetings
Corporate Injury Analysis work
Supply Chain ****** activities and meetings
Non******stock ETA modeling work (created ******)
Professional Development:
Participated in Looker Studio training for data visualization
Worked on Google Maps Optimization POC
Set up Gemini in VSCode
Explored Jira metrics via API
People Management:
Reached out to ****** about a ******
Provided feedback on ******&amp;#39;s Flow Metrics presentation
Worked with various team members including ******, ******, ******, and ******
Your month shows a balanced life with consistent attention to physical fitness, spiritual growth, family time, and professional responsibilities, with a particular focus on data and supply chain projects at work.
&lt;/code>&lt;/pre>&lt;p>This was great! For years, my Second Brain has been a storage device. I had the ability to go back and manually retrieve that information, but I had to read the notes into my short-term (actual) brain, and hold it there while I search for other information to connect it to. Obsidian and the Second Brain method make this simpler by encouraging the use of internal links in notes, but now I had another tool for synthesizing meaningful information from all these connections!&lt;/p>
&lt;h3 id="creating-notes">Creating Notes&lt;/h3>
&lt;p>Equipped with a tool for analyzing my second brain, I turned toward project management. I&amp;rsquo;ve had a few ideas for side projects that I wanted to flesh out a bit. I&amp;rsquo;ve worked with LLMs in the past to bounce ideas off and refine some thoughts, but now I could generate documentation around these ideas, store that information, and retrieve it later for ongoing processing and development! I took a conversation about a project I&amp;rsquo;m thinking through, described my desired goal, and then asked Claude to develop a plan for a low-code, low-cost MVP to test market fit. It described the approach, I refined it a bit, and then asked Claude to store the project documentation in my Obsidian Vault. Boom, project plan and action steps created!&lt;/p>
&lt;p>&lt;img alt="Project Plan" loading="lazy" src="https://brettgfitzgerald.com/posts/mcp-server-experiences/project-plan.jpg">&lt;/p>
&lt;h3 id="reflection">Reflection&lt;/h3>
&lt;p>MCP Servers seem extremely powerful. For such a long time, LLMs have seemed contained to limited use cases. Plugins for code editors have allowed functionality in coding and chatbots are common. Further integrations have required the use of APIs and coding to leverage the power of LLMs in other contexts. Now, with MCP Servers, it really feels like we have simple-to-create interfaces that allow LLMs to interact with the rest of the digital world. What will you create?&lt;/p></description></item><item><title>Video Compression Analysis</title><link>https://brettgfitzgerald.com/posts/video-compression-analysis/</link><pubDate>Wed, 12 Feb 2025 05:00:00 -0500</pubDate><guid>https://brettgfitzgerald.com/posts/video-compression-analysis/</guid><description>&lt;h2 id="a-videography-hobbyist">A videography hobbyist&lt;/h2>
&lt;p>In my free time, I like shooting videos of my family&amp;rsquo;s adventures and doing some basic editing. I shoot on my cellphone and a GoPro. For the past several years, I have rendered my final projects in 1080p at 24 frames per second. I liked the ability to shoot in 4k and still &amp;ldquo;zoom in&amp;rdquo; digitally to 1080. That also let me shoot slow motion video at 1080, and match my final render resolution. I recently got a newer GoPro, so now I can shoot 4k at 120 fps, which allows me slow down to 20% speed if I render my final project at 24 fps.&lt;/p>
&lt;p>With this advent of being able to shoot slow motion in 4k resolution, I decided to start rendering my projects in 4k, by default. I&amp;rsquo;m also experimenting with doing very quick edits, just splicing the day&amp;rsquo;s footage together, applying automatic color balancing per-clip, and then rendering at 60fps. This is more of a &amp;ldquo;home movie&amp;rdquo; of a day or event, rather than a curated, edited highlight video. I do all this in Davinci Resolve. Previously, I would be able to render my 1080 videos at 24fps and be happy with the file size and quality of picture. Now that I am rendering at four times the resolution and two and a half times the framerate, my output filesize has ballooned, and I need to pay better attention to my compression.&lt;/p>
&lt;p>I want to find a good balance between output filesize and quality for my home movies.&lt;/p>
&lt;h2 id="comparison-of-projects">Comparison of projects&lt;/h2>
&lt;p>In the past, I would shoot for around 100 megabytes per minute of rendered video. So a 5 minute video, rendered at a resolution of 1080, at 24 frames per second would come in around 500 MB. For videos I really spent time on, I would bump up my quality settings and I&amp;rsquo;d be happy with a 3 gig file for a 5 minute video.&lt;/p>
&lt;p>I recently rendered a video using Davinci Resolve&amp;rsquo;s 4k &amp;ldquo;Master&amp;rdquo; preset. So a resolution of 4k, at 60 frames per second, and a duration of 22 minutes came in at a whopping 75 gigabytes (~3.4 GB / min). I used Resolve&amp;rsquo;s &amp;ldquo;YouTube&amp;rdquo; preset, and that reduced the filesize to 1.8 GB.(~80 MB / min). That is a significant difference!&lt;/p>
&lt;p>For reference, my input files, shot on the GoPro Hero 13 were shot in 4k, mostly at 120 fps. They totaled 18.2GB, so my rendered file was actually four times larger than my source material!&lt;/p>
&lt;p>The two questions I have are:&lt;/p>
&lt;ol>
&lt;li>What is the difference in output files between these two?&lt;/li>
&lt;li>Is there a noticeable difference in visible quality?&lt;/li>
&lt;/ol>
&lt;h2 id="differences-in-objective-data">Differences in objective data&lt;/h2>
&lt;p>I wrote a &lt;a href="https://gist.github.com/controversy187/0d33948ba3afeb5ba4c4d2fb9ae8113f">python script&lt;/a> that compares various aspects of the videos. I also ran them through the various presets in &lt;a href="https://handbrake.fr/">Handbrake&lt;/a> to see how they compare. The video is 21:49 long. These are the results of that comparison, in order of increasing filesize.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Filename&lt;/th>
&lt;th>Bitrate (kbps)&lt;/th>
&lt;th>Resolution&lt;/th>
&lt;th>Framerate (FPS)&lt;/th>
&lt;th>Video Codec&lt;/th>
&lt;th>Filesize&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Source Video (Sample).MP4&lt;/td>
&lt;td>120000&lt;/td>
&lt;td>3840x2160&lt;/td>
&lt;td>119.88&lt;/td>
&lt;td>hevc&lt;/td>
&lt;td>67 &lt;strong>MB&lt;/strong>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Resolve - YouTube - h264.mp4&lt;/td>
&lt;td>11618&lt;/td>
&lt;td>3840x2160&lt;/td>
&lt;td>60&lt;/td>
&lt;td>h264&lt;/td>
&lt;td>1.8 GB&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Resolve - YouTube - h265.mp4&lt;/td>
&lt;td>10566&lt;/td>
&lt;td>3840x2160&lt;/td>
&lt;td>60&lt;/td>
&lt;td>hevc&lt;/td>
&lt;td>1.7 GB&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Resolve - Master - h264 - HandBrake - Fast.mp4&lt;/td>
&lt;td>37948&lt;/td>
&lt;td>3840x2160&lt;/td>
&lt;td>60&lt;/td>
&lt;td>hevc&lt;/td>
&lt;td>6 GB&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Resolve - Master - h264 - HandBrake - VeryFast.mp4&lt;/td>
&lt;td>41025&lt;/td>
&lt;td>3840x2160&lt;/td>
&lt;td>60&lt;/td>
&lt;td>hevc&lt;/td>
&lt;td>6.5 GB&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Resolve - Master - h264 - HandBrake - HQ.mp4&lt;/td>
&lt;td>57001&lt;/td>
&lt;td>3840x2160&lt;/td>
&lt;td>60&lt;/td>
&lt;td>hevc&lt;/td>
&lt;td>9 GB&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Resolve - Master - h264 - HandBrake - Super HQ.mp4&lt;/td>
&lt;td>78210&lt;/td>
&lt;td>3840x2160&lt;/td>
&lt;td>60&lt;/td>
&lt;td>hevc&lt;/td>
&lt;td>12.5 GB&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Resolve - Master - h265.mp4&lt;/td>
&lt;td>473927&lt;/td>
&lt;td>3840x2160&lt;/td>
&lt;td>60&lt;/td>
&lt;td>h264&lt;/td>
&lt;td>75.7 GB&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Resolve - Master - h264.mp4&lt;/td>
&lt;td>474208&lt;/td>
&lt;td>3840x2160&lt;/td>
&lt;td>60&lt;/td>
&lt;td>h264&lt;/td>
&lt;td>75.8 GB&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Obviously, Handbrake is going a good job at compressing the video, and lowering the bitrate, thus reducing filesize. But how do the videos actually &lt;em>look&lt;/em>?&lt;/p>
&lt;h2 id="subjective-comparison">Subjective comparison&lt;/h2>
&lt;p>Here are images captured from each of the above videos.&lt;/p>
&lt;div id="gallery">
&lt;a href="images/Resolve - YouTube - h264.jpg" data-sub-html="Davinci Resolve, YouTube preset, h264">
&lt;img src="images/Resolve - YouTube - h264.jpg" width="100%">
Davinci Resolve, YouTube preset, h264
&lt;/a>
&lt;a href="images/Resolve - YouTube - h265.jpg" data-sub-html="Davinci Resolve, YouTube preset, h265">
&lt;img src="images/Resolve - YouTube - h265.jpg" width="100%">
Davinci Resolve, YouTube Preset, h265
&lt;/a>
&lt;a href="images/Resolve - Master - h264 - HandBrake - Fast.jpg" data-sub-html="Handbrake, Fast">
&lt;img src="images/Resolve - Master - h264 - HandBrake - Fast.jpg" width="100%">
Handbrake, Fast
&lt;/a>
&lt;a href="images/Resolve - Master - h264 - HandBrake - VeryFast.jpg" data-sub-html="Handbrake, Very Fast">
&lt;img src="images/Resolve - Master - h264 - HandBrake - VeryFast.jpg" width="100%">
Handbrake, Very Fast
&lt;/a>
&lt;a href="images/Resolve - Master - h264 - HandBrake - HQ.jpg" data-sub-html="Handbrake, High Quality">
&lt;img src="images/Resolve - Master - h264 - HandBrake - HQ.jpg" width="100%">
Handbrake, High Quality
&lt;/a>
&lt;a href="images/Resolve - Master - h264 - HandBrake - Super HQ.jpg" data-sub-html="Handbrake, Super High Quality">
&lt;img src="images/Resolve - Master - h264 - HandBrake - Super HQ.jpg" width="100%">
Handbrake, Super High Quality
&lt;/a>
&lt;a href="images/Resolve - Master - h264.jpg" data-sub-html="Davinci Resolve, Master - h264">
&lt;img src="images/Resolve - Master - h264.jpg" width="100%">
Davinci Resolve, Master - h264
&lt;/a>
&lt;a href="images/Resolve - Master - h265.jpg" data-sub-html="Davinci Resolve, Master - h265">
&lt;img src="images/Resolve - Master - h265.jpg" width="100%">
Davinci Resolve, Master - h265
&lt;/a>
&lt;/div>
&lt;p>In these very specific examples, you can immediately see that the DaVinci Resolve YouTube presets are not good. The h264 version shows artifiacts on the right side of the frame and all detail in the snow on the ground is completely lost. Interestingly, the h265 codec doesn&amp;rsquo;t lose as much detail, and is slightly smaller. In the case were you need a small file, it seems like the h265 does a better job at these lower bitrates.&lt;/p>
&lt;p>When we jump up into the Handbrake re-encodes, things get noticeably better. Honestly, from the still frames it&amp;rsquo;s very hard (for me) to tell the difference between these images, all the way through to the masters. Even when I watch the playback of the videos themselves, I&amp;rsquo;m hard pressed to see any difference. It could be that the source clips themselves only have a 120Mbps bitrate, and we&amp;rsquo;re re-encoding at a higher bitrate for the masters (474Mbps).&lt;/p>
&lt;h2 id="conclusions">Conclusions&lt;/h2>
&lt;p>To really judge this fairly, I probably should have rendered everything out from DaVinci Resolve and manually adjusted the bitrate. Based on these tests, though, I&amp;rsquo;m not seeing a noticeable loss in quality between the 474Mbps best quality from Resolve and a re-encoded to 78Mbps in Handbrake. For the time being, I&amp;rsquo;m planning to render out from Resolve and limiting my bitrate to 80Mbps. That&amp;rsquo;s only 590 MB or so per minute of video, which isn&amp;rsquo;t bad for what I&amp;rsquo;m doing with them.&lt;/p></description></item><item><title>Build a Large Language Model From Scratch</title><link>https://brettgfitzgerald.com/posts/build-a-large-language-model/</link><pubDate>Thu, 06 Feb 2025 12:57:27 -0500</pubDate><guid>https://brettgfitzgerald.com/posts/build-a-large-language-model/</guid><description>&lt;h2 id="building-a-large-language-model-from-scratch">Building a large language model from scratch&lt;/h2>
&lt;p>I&amp;rsquo;m a machine learning / A.I. hobbyist. The technologies fascinate me, and I can&amp;rsquo;t seem to learn enough about them. Sebastian Raschka&amp;rsquo;s book, Build a Large Language Model (From Scratch) caught my eye. I don&amp;rsquo;t recall how I stumbled on it, but I found it when it was still in early access from Manning Publications. I purchased it, and started working through it as the final chapters were being written and released. I just completed the book and all the included work and loved every minute of it.&lt;/p>
&lt;p>&lt;img alt="Build a Large Language Model From Scratch by Sebastian Raschka" loading="lazy" src="https://brettgfitzgerald.com/posts/build-a-large-language-model/llm-book.jpg">&lt;/p>
&lt;h2 id="my-approach">My approach&lt;/h2>
&lt;p>A while ago, I read some advice about learning programming from digital books and tutorials. The advice was to never copy and paste code from samples but to hand-type all the code. I took that approach with this book. I typed every single line of code (except for a couple of blocks which were highly repetitive and long). You can see all my work here: &lt;a href="https://github.com/controversy187/build-a-large-language-model">https://github.com/controversy187/build-a-large-language-model&lt;/a>&lt;/p>
&lt;p>I did my best to work in section chunks. I didn&amp;rsquo;t want to start a section unless I had the time dedicated to completing it. Some sections are pretty short, others are fairly involved and time-consuming.&lt;/p>
&lt;p>I built this in Jupyter Notebooks on my laptop, which is pretty underpowered for this type of work. The premise of the book was that you can build an LLM on consumer hardware, and it can perform decently well. As I&amp;rsquo;m writing this, I&amp;rsquo;m currently fine-tuning my model locally. My model is about 50 steps into a 230-step tuning, and I just crossed the 20-minute execution time mark. The earlier code samples ran quicker, but the last few sections used larger models, which slowed things down considerably.&lt;/p>
&lt;p>I didn&amp;rsquo;t do most of the supplemental exercises. I tend to have an &amp;ldquo;I want to do ALL THE THINGS!&amp;rdquo; personality. The drawback is that if I take the time to do all the things, I eventually get long-term distracted and never actually finish what I started. So I sort of rushed through this book. I even took several weeks off around Christmas and New Year&amp;rsquo;s. But I got back into it and powered through the last few chapters.&lt;/p>
&lt;p>So, more or less, I read through the chapters and wrote all the mandatory coding assignments.&lt;/p>
&lt;h2 id="learnings">Learnings&lt;/h2>
&lt;p>What can I tell you about large language models? A lot more than I could before I started this book, but certainly not all the things the author attempted to teach me. I&amp;rsquo;ll summarize my understanding, but I could be wrong about some of these things, and I most certainly forgot or misunderstood others.&lt;/p>
&lt;h3 id="tokenization--vocabulary">Tokenization &amp;amp; Vocabulary&lt;/h3>
&lt;p>A large language model starts its life by building a vocabulary of text. A massive amount of text is distilled down into a list of unique words. Each word is then translated into an integer because computers like numbers more than they like words. This process is referred to as &amp;ldquo;tokenization&amp;rdquo;, where the word is replaced with a numerical token. So now we have a list of unique tokens, which is the vocabulary of the large language model.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Build a more advanced tokenizer&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>text &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Hello, world. Is this-- a test?&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>result &lt;span style="color:#f92672">=&lt;/span> re&lt;span style="color:#f92672">.&lt;/span>split(&lt;span style="color:#e6db74">r&lt;/span>&lt;span style="color:#e6db74">&amp;#39;([,.:;?_!&amp;#34;()&lt;/span>&lt;span style="color:#ae81ff">\&amp;#39;&lt;/span>&lt;span style="color:#e6db74">]|--|\s)&amp;#39;&lt;/span>, text)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>result &lt;span style="color:#f92672">=&lt;/span> [item&lt;span style="color:#f92672">.&lt;/span>strip() &lt;span style="color:#66d9ef">for&lt;/span> item &lt;span style="color:#f92672">in&lt;/span> result &lt;span style="color:#66d9ef">if&lt;/span> item&lt;span style="color:#f92672">.&lt;/span>strip()]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(result)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Outputs &amp;#34;[&amp;#39;Hello&amp;#39;, &amp;#39;,&amp;#39;, &amp;#39;world&amp;#39;, &amp;#39;.&amp;#39;, &amp;#39;Is&amp;#39;, &amp;#39;this&amp;#39;, &amp;#39;--&amp;#39;, &amp;#39;a&amp;#39;, &amp;#39;test&amp;#39;, &amp;#39;?&amp;#39;]&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>all_words &lt;span style="color:#f92672">=&lt;/span> sorted(set(result))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>vocab_size &lt;span style="color:#f92672">=&lt;/span> len(all_words)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(vocab_size)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Outputs 10&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Display the first 51 tokens in our vocabulary.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>vocab &lt;span style="color:#f92672">=&lt;/span> {token:integer &lt;span style="color:#66d9ef">for&lt;/span> integer,token &lt;span style="color:#f92672">in&lt;/span> enumerate(all_words)}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> i, item &lt;span style="color:#f92672">in&lt;/span> enumerate(vocab&lt;span style="color:#f92672">.&lt;/span>items()):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(item)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Outputs:&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>(&lt;span style="color:#e6db74">&amp;#39;,&amp;#39;&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>(&lt;span style="color:#e6db74">&amp;#39;--&amp;#39;&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>(&lt;span style="color:#e6db74">&amp;#39;.&amp;#39;&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>(&lt;span style="color:#e6db74">&amp;#39;?&amp;#39;&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>(&lt;span style="color:#e6db74">&amp;#39;Hello&amp;#39;&lt;/span>, &lt;span style="color:#ae81ff">4&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>(&lt;span style="color:#e6db74">&amp;#39;Is&amp;#39;&lt;/span>, &lt;span style="color:#ae81ff">5&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>(&lt;span style="color:#e6db74">&amp;#39;a&amp;#39;&lt;/span>, &lt;span style="color:#ae81ff">6&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>(&lt;span style="color:#e6db74">&amp;#39;test&amp;#39;&lt;/span>, &lt;span style="color:#ae81ff">7&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>(&lt;span style="color:#e6db74">&amp;#39;this&amp;#39;&lt;/span>, &lt;span style="color:#ae81ff">8&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>(&lt;span style="color:#e6db74">&amp;#39;world&amp;#39;&lt;/span>, &lt;span style="color:#ae81ff">9&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># In this example, the id 9 represents the word &amp;#34;world&amp;#34;. 5 represents &amp;#34;Is&amp;#34;. etc.&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This is where my understanding gets fuzzy. We didn&amp;rsquo;t get very far before that happened, &amp;rsquo;eh? Now, we take that massive amount of text we were using earlier to create the vocabulary (or a subset, or totally different text), and we tokenize the entire text. We do this by using the vocabulary we built previously and substituting the words in the training text for their equivalent token value. This is now our training text.&lt;/p>
&lt;h3 id="model-training--relationships">Model Training &amp;amp; Relationships&lt;/h3>
&lt;p>With that complete, we can &amp;ldquo;train&amp;rdquo; the model. This process involves taking each token in the vocabulary and building a relationship to each other token in the vocabulary, based on those tokens&amp;rsquo; relative positions to each other in the training text. So if the word &amp;ldquo;cat&amp;rdquo; is followed by the word &amp;ldquo;jump&amp;rdquo;, the model records that relationship. But it also records the relationship of the word &amp;ldquo;cat&amp;rdquo; to other words in the text. So &amp;ldquo;jump&amp;rdquo; follows &amp;ldquo;cat&amp;rdquo;, but maybe it does so more frequently when they are close to the word &amp;ldquo;mouse&amp;rdquo;. And maybe less frequently when they are close to the word &amp;ldquo;nap&amp;rdquo;. Recording ALL these relationships would require a massive dataset, so the relationships are mathematically reduced and approximated. There are definitely more technical terms to use, and the book went into them. I definitely forget them, though.&lt;/p>
&lt;h3 id="text-generation-process">Text Generation Process&lt;/h3>
&lt;p>Now, if you provide a starter text to the model, it will try to complete the text for you. Continuing our example, if I gave the model the text &amp;ldquo;My cat saw a mouse and it&amp;rdquo;, based on the word cat being close to the word mouse, it might predict the word &amp;ldquo;jumped&amp;rdquo; to come next. So it appends the word &amp;ldquo;jumped&amp;rdquo; to the text I submitted, and then it takes that whole new sentence and feeds it back into itself. So now the input text is &amp;ldquo;My cat saw a mouse and it jumped&amp;rdquo;. The next output word could be &amp;ldquo;on&amp;rdquo;, so it appends that word and feeds this concatenated output back into its input.&lt;/p>
&lt;p>&lt;del>Every time it does a loop like this, it tokenizes the entire input (or up to a limit, known as a context limit or context window) and then calculates the most likely next token, then converts it all back to text for us to read.&lt;/del> &lt;em>&lt;a href="#update-2025-02-17">See update&lt;/a>&lt;/em>&lt;/p>
&lt;h3 id="model-weights--distribution">Model Weights &amp;amp; Distribution&lt;/h3>
&lt;p>&lt;del>Saving all those relationships between the tokens are known as the &amp;ldquo;weights&amp;rdquo; of the model.&lt;/del> &lt;em>&lt;a href="#update-2025-02-17">See update&lt;/a>&lt;/em> Those can be distributed, so if you train a model on a given training text, you can give that to your friends and they can use those model weights to predict text similar to that training text.&lt;/p>
&lt;h3 id="fine-tuning">Fine Tuning&lt;/h3>
&lt;p>Fine-tuning is the process of training a model for specific&amp;hellip; things. My mind is getting fuzzier here, so I&amp;rsquo;m not going to go into this deeper. Suffice it to say, that you start with a base language model and continue to train it using specific input and output pairs. In the book, we built a spam classifier that determined if a given message was spam or not, as well as a model that will follow instructions. That&amp;rsquo;s actually the one that&amp;rsquo;s being trained right now as I write this post, so I&amp;rsquo;m not sure how it will turn out. Based on the fact that it&amp;rsquo;s published in a book, I think it will come out just fine.&lt;/p>
&lt;p>So while I&amp;rsquo;m not completely done with the book, I&amp;rsquo;m very nearly there. I did learn a lot of great concepts, although obviously some of them weren&amp;rsquo;t retained. It would probably behoove me to go back through the book again and quickly breeze through it, in order to refresh my memory and cement my learnings.&lt;/p>
&lt;h2 id="meta-learnings">Meta learnings&lt;/h2>
&lt;p>Other than the technical aspects of Large Language Models, what else did I learn through this experience?&lt;/p>
&lt;p>Through my experiment with typing all the code samples by hand, I can say that my time would have been better spent with a different approach. If I do this again, I&amp;rsquo;ll probably not type all the code snippets, but rather &amp;ldquo;type&amp;rdquo; them in my mind, and really understand what each line does. The times I learned the most were actually when I made a typo and had to go back through my code to debug it. That forced me to understand what was happening so I could figure out what went wrong.&lt;/p>
&lt;p>I learn better with paper, rather than a digital book. I don&amp;rsquo;t know why. I had both available to me, and I read the first couple of chapters in the paper book. That information stuck better. Maybe because it was earlier in the book and simpler to understand, or maybe the format played into it. But I enjoyed it better, regardless.&lt;/p>
&lt;p>I didn&amp;rsquo;t have to &amp;ldquo;figure out&amp;rdquo; anything, and I think that hampered my learning. There are supplemental exercises in the book, where the author gives you a problem and you have to figure out how to solve it. The answers are given in his GitHub repository. That would have slowed me down a lot, but I&amp;rsquo;m very confident that I would have learned the material better.&lt;/p>
&lt;h2 id="whats-next">What&amp;rsquo;s next?&lt;/h2>
&lt;p>I&amp;rsquo;m torn right now. I want to understand this material better, but I wonder if getting into lower-level, specific material might help me understand AI and machine learning better. What will likely happen is that I&amp;rsquo;ll copy and paste this content into Claude.ai and suggest a path forward for me.&lt;/p>
&lt;hr>
&lt;h2 id="update-2025-02-17">Update: 2025-02-17&lt;/h2>
&lt;p>&lt;a href="https://www.linkedin.com/in/sebastianraschka/">Sebastian Raschka&lt;/a> sent me a kind message in response to this post and clarified some of my thinking. To quote him:&lt;/p>
&lt;blockquote>
&lt;ol>
&lt;li>&amp;ldquo;Every time it does a loop like this, it tokenizes the entire input (or up to a limit, known as a context limit or context window)&amp;rdquo;. You do this initially when you parse the input text. But then you technically don&amp;rsquo;t need to re-tokenize anything. You can leave the generated output in the tokenized form when creating the next token.&lt;/li>
&lt;/ol>
&lt;p>What I mean is if the text is&lt;/p>
&lt;p>&amp;ldquo;My cat saw a mouse&amp;rdquo;&lt;/p>
&lt;p>The tokens might be &amp;ldquo;123 1 5 6 99&amp;rdquo; (numbers are arbitrary examples). Then the LLM generates the token 801 for &amp;ldquo;jump&amp;rdquo;. Then you simply use &amp;ldquo;123 1 5 6 99 801&amp;rdquo; as the input for the next word.&lt;/p>
&lt;p>When you show the output to the user, then you convert back into text.&lt;/p>
&lt;ol start="2">
&lt;li>&amp;ldquo;Saving all those relationships between the tokens are known as the “weights” of the model.&amp;rdquo;&lt;/li>
&lt;/ol>
&lt;p>I would say that relationships between tokens are the attention scores. The model weights are more like values that are involved in computing things like the attention scores (and other things).&lt;/p>
&lt;p>Now that you finished the book, in case you are bored, I do also have some more materials as bonus material in the GitHub repository.&lt;/p>
&lt;p>I&amp;rsquo;d say the GPT-&amp;gt;Llama conversion (&lt;a href="https://github.com/rasbt/LLMs-from-scratch/tree/main/ch05/07_gpt_to_llama">https://github.com/rasbt/LLMs-from-scratch/tree/main/ch05/07_gpt_to_llama&lt;/a>) and the DPO preference tuning (&lt;a href="https://github.com/rasbt/LLMs-from-scratch/blob/main/ch07/04_preference-tuning-with-dpo/dpo-from-scratch.ipynb">https://github.com/rasbt/LLMs-from-scratch/blob/main/ch07/04_preference-tuning-with-dpo/dpo-from-scratch.ipynb&lt;/a>) are maybe the most interesting ones.&lt;/p>
&lt;p>I also just uploaded some PyTorch tips for increasing the training speed of the model: &lt;a href="https://github.com/rasbt/LLMs-from-scratch/tree/main/ch05/10_llm-training-speed">https://github.com/rasbt/LLMs-from-scratch/tree/main/ch05/10_llm-training-speed&lt;/a>&lt;/p>
&lt;p>These materials are less polished than the book itself, but maybe you&amp;rsquo;ll still find them useful!&lt;/p>&lt;/blockquote></description></item><item><title>New Blog</title><link>https://brettgfitzgerald.com/posts/new-blog/</link><pubDate>Wed, 05 Feb 2025 00:00:00 +0000</pubDate><guid>https://brettgfitzgerald.com/posts/new-blog/</guid><description>&lt;h2 id="why">Why?&lt;/h2>
&lt;p>Does the internet need another blog? Definitively, no. Do I have original insights that you will benefit from reading? Most likely not. So what&amp;rsquo;s the point of this blog?&lt;/p>
&lt;p>I recently changed jobs, and I&amp;rsquo;m learning a lot. I retain information better when I describe it to someone. I also have a fear that if I constantly regurgitate my ongoing education to my close family, they will eventually want to murder me. That&amp;rsquo;s where this blog comes in. I&amp;rsquo;m going to teach you what I&amp;rsquo;m learning, so I can learn it better.&lt;/p>
&lt;p>Inevitably, I&amp;rsquo;ll forget about this blog. Posts will become less frequent, and then stop completely. At some point, I&amp;rsquo;ll just stop writing here completely. After a while, I&amp;rsquo;ll find a new use for my domain name, and this will cease to exist, except in the ever growing dataset of archive.org. So, let&amp;rsquo;s get on with it!&lt;/p></description></item></channel></rss>